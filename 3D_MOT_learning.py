'''

这个文档不仅仅是3D的MOT，是整个MOT领域的，许多2D和3D的技巧是通用的

https://blog.csdn.net/qq_42191914/article/details/105057117   这篇文章讲解了MOTA和IDF1之间的优劣




JDE:   https://zhuanlan.zhihu.com/p/243290960
	tracking by detection是非常常见的MOT范式，但是目前MOT领域为了平衡追踪速度和精度，慢慢放弃了这种范式，转而投入将检测与embedding/匹配进行结合的范式研究中。本文介绍的JDE就是一个网络同时输出图像画面中的检测框位置和检测框内物体的embedding，从而加速MOT的速度。
	但是值得注意的是，JDE只是同时输出了检测框和embedding信息。后面还是要通过卡尔曼滤波和匈牙利算法进行目标的匹配。总的来说，还是分为检测和匹配双阶段。
	后面将介绍一些最新的MOT方法，比如CenterTrack，他采用了一种新的方式，同时输出检测和匹配的信息，比JDE更方便。
所以作者引入了全连接层将embedding信息转化为track ID分类信息。代码中设置了14455个输出节点，这个非常大呀，具体设置的依据是什么，可能和训练数据集的物体数量有关吧。
	细看了代码，nID=14455是作者统计了所有训练集的identity总数。具体代码可见utils/datasets.py中的JointDataset Class
	然后就是三个损失函数，置信度、box、embedding（全连接交叉熵分类）
	但是值得注意的是，JDE只是同时输出了检测框和embedding信息。后面还是要通过卡尔曼滤波和匈牙利算法进行目标的匹配。总的来说，还是分为检测和匹配双阶段。



CenterTrack：https://zhuanlan.zhihu.com/p/252813609
	目标检测和数据关联统一
	Objects as Points 这个是centernet的论文；CenterTrack的论文叫做《Tracking Objects as Points》。
	输出三个分支，分别为：
    （1） HeatMap，大小为（W/4,H/4,80），输出不同类别（80个类别）物体中心点的位置
	（2） Offset，大小为（W/4,H/4,2），对HeatMap的输出进行精炼，提高定位准确度
	（3） Height&Width,大小为（W/4,H/4,2），预测以关键点为中心的检测框的宽高
	通篇来看发现CenterTrack的输入为两个RGB图片（当前帧和前一帧）+一张heatmap图（前一帧中物体中心分布的热力图），这不比CenterTrack多了一张RGB（3通道）和一个单通道的heatmap嘛。
	所以其输入就是：
	（1） 当前帧的RGB图片，大小为（W,H,3）
	（2） 前一帧的RGB图片，大小为（W,H,3）
	（3） 前一帧预测的heatmap,大小为（W,H,1）
	最重要的是三个不同的输入需要怎么进行信息的融合呢？
	作者在这里用了非常简单的方法：先是通过简单的卷积层、批归一化层和激活函数，然后按位相加即可。注意是加不是concat。
	接着按位相加的特征图作为一个特征提取网络的输入，作者在代码中给出了一些选项：就是主干网络的选取，什么dla啊之类的网络，这些网络都会经历一系列下采样与一定比例的上采样，输入特征图宽高为（W,H）,输出特征图宽高为（W/4,H/4）。
	这里不妨以 PoseResNet为例，该特征提取网络非常简单，先通过一个ResNet下采样32倍（我相信大家都熟悉），获得特征图宽高大小（W/32,H/32）。然后以该特征图为基础执行3次上采样（反卷积，步长为2）。那么最终会获得一个宽高为（W/4,H/4）的特征图。
	下面就是四个输出：
	每个head由两个卷积层，中间一个RELU激活函数组成，非常简单。最终获得的四个输出特征图如下：
    （1）HeatMap，大小为（W/4,H/4,80）,检测框中心点位置分布热力图
	（2）offset，大小为（W/4,H/4,1），相关点为前景中心的置信度图    代码里HeatMap/Confidence同一个东西？
	（对的，源码中四层输出分别为：['hm', 'reg'(=offset), 'wh', 'tracking']。在centerNet中，作者提到直接使用heatmap中峰值的预测值作为该点预测的置信度）
	（3）Height&Width,大小为（W/4,H/4,2），点对应的检测框的宽高
	（4）Displacement prediction, 大小为（W/4,H/4,2），检测框中心点在前后帧的位移（有点类似于光流）   他这边写的shape可能是有问题的，具体的就需要看代码了解了
	Displacement prediction细节：
	就是计算两帧物体的中心点的位移，得到了距离和真值做loss   ********实际上这个中心点之间是怎么匹配的********？
	这个CenterTrack只关联连续两帧之间的检测框，那么很难形成长期的关联和依赖，这样其实非常容易产生ID切换等情况的发生。但是作者论文中提到，也就是虽然这种CenterTrack只关联连续两帧之间的检测框，但是却很好地平衡了检测速度和检测精度，通过实验发现，该办法精度还是不错的。
	

FairMOT：https://zhuanlan.zhihu.com/p/259356109
	JDE的不足：
	JDE的检测方式同时提取检测框和检测框内物体的Re-ID信息（低维的向量信息）
	而基于Anchor-Based 检测器产生出来的anchor并不适合去学习合适的Re-ID信息（anchor学REID？），原因有二，其一是一个物体可能被多个anchor负责并进行检测，这会导致严重的网络模糊性（ambiguities for the network）。第二个原因是实际物体的中心可能与负责对该物体进行检测的anchor中心有偏差。
	reid多层特征融合：到底选择多大的Re-ID维度来存储Re-ID信息呢？
	之前的一些Re-ID方法中都会选择一些高维度的特征来存储Re-ID信息，但是作者在FairMOT实验中发现使用低维度的特征更适用于JDE这种MOT方法。因为在MOT的一些benchmarks中并没有那么像Re-ID那么多的数据，维度设置大了容易过拟合。
	主干网络用的DLA，这个网络刚好就是那种多融合的网络，恰好符合Re-ID信息需要多层信息融合的特点。
	采用这个网络的原因：当然了，和分类任务或者基于anchor的检测任务不同（这些任务往往不需要多高的输出分辨率），基于关键点的检测（anchor-free）往往需要分辨率更高（一般为stride=4）的输出特征图，这样不会产生较大的中心点偏移了。所以作者采用了一种形似encoder-decoder的DLA网络作为特征提取，
	Encoder-decoder网络提取的（stride=4）高分辨率特征图将被作为四个分支的特征图。其中三个被用来检测物体（Detection），一个被用来输出物体的Re-ID信息(Re-ID)。
	四个head都是走了正常的卷积通道得到的shape不一样的输出。
	网络的最后输出为：
    （1）heatmap，形状为（1，H，W）,这里好像和其他anchor-free方法输出的featmap不同，这里只有一个通道，而其他方法有类别数个通达（80居多）。这个需要研究研究啊
	（2）center offset，形状为（2，H，W），和centerNet中的offset一样，弥补由于下采样产生的轻微的offset
	（3）bbox size，形状为（2，H，W），仅仅知道中心点位置还不行，还需要用这个特征图来计算中心点对应检测框的宽高
	（4）Re-ID Embedding，形状为（128，H，W），也就是每个物体用一个128维向量表示。
	分别对应的损失函数
	（1）还有一些细节包括如何将物体的中心映射到heatmap上，这在之前对CenterNet，CenterTrack的解析中也提到过。作者按照高斯分布将物体的中心映射到了heatmap上，然后使用变形的focal loss进行预测的heatmap和实际真实的heatmap损失函数的求解
	（2）作者仅仅用了两个L1损失就实现了。offset和size。
	（3）reid损失，交叉熵
	获得物体的位置和Re-ID信息后，配合卡尔曼滤波求解其代价矩阵（cost matrix），然后利用匈牙利算法进行匹配，FairMOT就结束了。
	有空读读论文



ByteTrack：  作者的原文章https://zhuanlan.zhihu.com/p/421264325
	简单的概述：沿着多目标跟踪（MOT）中tracking-by-detection的范式，我们提出了一种简单高效的数据关联方法BYTE。 利用检测框和跟踪轨迹之间的相似性，在保留高分检测结果的同时，从低分检测结果中去除背景，挖掘出真正的物体（遮挡、模糊等困难样本），从而降低漏检并提高轨迹的连贯性。BYTE能轻松应用到9种state-of-the-art的MOT方法中，并取得1-10个点不等的IDF1指标的提升。基于BYTE我们提出了一个跟踪方法ByteTrack，首次以30 FPS的运行速度在MOT17上取得80.3 MOTA，77.3 IDF1和63.1 HOTA，目前位居MOTChallenge榜单第一。我们还在开源代码中加入了将BYTE应用到不同MOT方法中的教程以及ByteTrack的部署代码。
	IDF1这个指标的半径是越大越好还是越小越好？ （https://www.csdn.net/tags/OtTaAg1sNzUwNjYtYmxvZwO0O0OO0O0O.html）  这篇文章对MOT的一些指标做了一个比较详细的介绍，可以看看，感觉这个IDF1是不是就是对目标长时间的跟踪的指标
	动机：Tracking-by-detection是MOT中的一个经典高效的流派，通过相似度（位置、外观、运动等信息）来关联检测框得到跟踪轨迹。由于视频中场景的复杂性，检测器无法得到完美的检测结果。为了处理true positive/false positive的trade-off，目前大部分MOT方法会选择一个阈值，只保留高于这个阈值的检测结果来做关联得到跟踪结果，低于这个阈值的检测结果直接丢弃。但是这样做合理吗？答案是否定的。黑格尔说过：“存在即合理。”低分检测框往往预示着物体的存在（例如遮挡严重的物体）。简单地把这些物体丢弃会给MOT带来不可逆转的错误，包括大量的漏检和轨迹中断，降低整体跟踪性能。
	byte部分：为了解决之前方法丢弃低分检测框的不合理性，我们提出了一种简单、高效、通用的数据关联方法BYTE (each detection box is a basic unit of the tracklet, as byte in computer program)。直接地将低分框和高分框放在一起与轨迹关联显然是不可取的，会带来很多的背景（false positive）。BYTE将高分框和低分框分开处理，利用低分检测框和跟踪轨迹之间的相似性，从低分框中挖掘出真正的物体，过滤掉背景。
	（1）BYTE会将每个检测框根据得分分成两类，高分框和低分框，总共进行两次匹配。
	（2）第一次使用高分框和之前的跟踪轨迹进行匹配。
	（3）第二次使用低分框和第一次没有匹配上高分框的跟踪轨迹（例如在当前帧受到严重遮挡导致得分下降的物体）进行匹配。（实际上我的理解就是低分框会有很多，然后找到没匹配上的track和最好的低分检测框匹配上）
	（4）对于没有匹配上跟踪轨迹，得分又足够高的检测框，我们对其新建一个跟踪轨迹。对于没有匹配上检测框的跟踪轨迹，我们会保留30帧，在其再次出现时再进行匹配。	（那他这个保留是怎么和后面匹配上的？也没有reid，物体运动了是怎么匹配的？默认匀速，卡尔曼照样更新，然后匹配？）
	我们认为，BYTE能work的原因是遮挡往往伴随着检测得分由高到低的缓慢降低：被遮挡物体在被遮挡之前是可视物体，检测分数较高，建立轨迹；当物体被遮挡时，通过检测框与轨迹的位置重合度就能把遮挡的物体从低分框中挖掘出来，保持轨迹的连贯性。
	ByteTrack使用当前性能非常优秀的检测器YOLOX得到检测结果。在数据关联的过程中，和SORT一样，只使用卡尔曼滤波来预测当前帧的跟踪轨迹在下一帧的位置，预测的框和实际的检测框之间的IoU作为两次匹配时的相似度，通过匈牙利算法完成匹配。这里值得注意的是我们没有使用ReID特征来计算外观相似度：
	（1）第一点是为了尽可能做到简单高速，第二点是我们发现在检测结果足够好的情况下，卡尔曼滤波的预测准确性非常高，能够代替ReID进行物体间的长时刻关联。实验中也发现加入ReID对跟踪结果没有提升。
	（2）如果需要引入ReID特征来计算外观相似度，可以参考我们开源代码中将BYTE应用到JDE，FairMOT等joint-detection-and-embedding方法中的教程。
	（3）ByteTrack只使用运动模型没有使用外观相似度能在MOT17，20取得高性能的本质原因是MOT数据集的运动模式比较单一（于是，我们提出了一个新数据DanceTrack，彩蛋！）



关于deepsort的马氏距离：
	显然当目标运动过程中的不确定度比较低（马氏距离小）的时候（也就是满足卡尔曼滤波算法的假设，即所有物体的运动具有一定规律，且没有什么遮挡），那么基于motion特征的方法，即上面提到的方法（可是视为改进的SORT）自然有效。
	马氏距离通过测量卡尔曼滤波器的追踪位置均值（mean track location）之间的标准差与检测框来计算状态估计间的不确定性
	就是倒卡方分布计算出来的95%置信区间作为马氏距离阈值，超过这个距离就是舍弃，不做匹配了。可以看代价矩阵。



UKF:
	里面有个关于噪声的一个问题：
	Hello, I just wonder How do you have the "noise standard deviation"? I find it have already a definition in you code, as:

	// Process noise standard deviation longitudinal acceleration in m/s^2
	std_a_ = 2.0;

	// Process noise standard deviation yaw acceleration in rad/s^2
	std_yawdd_ = 0.7;

    AdamShan
    AdamShan作者
    回复 Louis_CLS2018.01.19
    [点赞] 1
    Hi, Louis. The 'std_a_' and 'std_yawdd_' denote the standard deviations of the process noise (the longitudinal acceleration noise and yaw acceleration noise), so std_a_*std_a_ and std_yawdd_*std_yawdd_ are the variances. They are parameters that need to be tuned manually. The acceleration and yaw acceleration are different when tracking different objects. For example, in this blog, the linear acceleration is being modeled as a Gaussian distribution with mean zero and standard deviation std_a_ , in a Gaussian distribution, about 95% of values are within 2*std_a_. So if we choose 2.0 as the std_a_ , we except the acceleration of the tracking object are (-4, 4) m/s^2, which is appropriate for bicycle tracking in this blog. When tracking a vehicle, this parameter should be larger. I hope you have understand these two parameters. Good luck!
	
	翻译过来就是：
	嗨，路易斯。 'std_a_' 和 'std_yawdd_' 表示过程噪声（纵向加速度噪声和偏航加速度噪声）的标准偏差，因此 std_a_*std_a_ 和 std_yawdd_*std_yawdd_ 是方差。  它们是需要手动调整的参数。  跟踪不同物体时的加速度和偏航加速度是不同的。  例如，在本博客中，线性加速度被建模为均值为 0 且标准差为 std_a_ 的高斯分布，在高斯分布中，大约 95% 的值在 2*std_a_ 内。  因此，如果我们选择 2.0 作为 std_a_ ，我们除了跟踪对象的加速度为 (-4, 4) m/s^2 外，这适用于本博客中的自行车跟踪。  跟踪车辆时，此参数应较大。  我希望你已经了解这两个参数。  祝你好运！






关于数据关联：https://zhuanlan.zhihu.com/p/176851546   、 https://zhuanlan.zhihu.com/p/509109452
	这边主要围绕着PDA展开描述。
	当前的一些数学模型，运动学的，都是由运动方程（状态方程？）和观测方程组成的，其实就是卡尔曼滤波里面的运动和预测。一般先假设最简单的运动模型是线性的预测模型自然也是线性的，然后再去讨论非线性的该怎么优化
	正因为我需要知道拿到的观测值到底是那一个目标的观测值，所以我需要在update之前匹配，而在predict的时候预测观测值那就是套公式无所谓不需要匹配的。
	目标跟踪问题也涉及很多方面，譬如状态方程的选取、量测方程的选取、滤波方法的选取、数据关联、航迹管理、跟踪门等等。
	先回顾下卡尔曼滤波的一些基本的概念：
	卡尔曼滤波就是结合预测（先验）和测量更新（似然）的状态估计算法
	先验概率就是主观根据公式啥的算出来的、后验就是在相关的证据或者是背景纳入考虑后的条件概率、似然就是已知结果推测物体的固有属性的可能性
	***********后验正比于先验分布乘以似然***************
	1.先验状态概率密度  x-pred	描述了在k-1步预测第k步状态的概率密度	
	2.先验误差的协方差  p-pred	真实值和先验估计误差的协方差的大小，描述了预测状态和真实状态的误差的大小，描述一个不确定性，基于原始的不确定性和外部环境的误差得到的
		这边插入一下协方差矩阵的含义：表示变量和变量之间的关系，那么这个P矩阵应该是对称的，如果两个变量不相关，那么协方差就是0；一般我们也只给出P0，剩余的都是自己更新计算的；
		而对于噪声矩阵，噪声之间也是相互独立的，那么就是对角矩阵；
		P0 = Var⟨X0⟩ P的初值就是代表你对你估计的X0有多不确定。P0为0的时候就是说你对你给初值有着坚不可摧的信心。一般来说宁可设成单位阵都不会设成0的。
		卡尔曼滤波算法假设所有噪声都是零均值的白噪声，那么Q和R中的元素就是白噪声的方差，对角矩阵
		（所以协方差矩阵在卡尔曼滤波中就代表了【不确定度】，我们进行滤波的目的就是为了尽可能地减小这种【不确定度】，估计到true value）
		（如果P0、Q、R无法精确获得，只知道可能的取值范围，则采用可能的较大值（保守）。如果不确切知道Q、R、P0的准确先验信息，应适当增大Q的取值，以增大对实时量测值的利用权重，俗称调谐。但是调谐存在盲目性，无法知道Q要调到多大才行）     【https://www.zhihu.com/question/53788909/answer/153405833】
		实际中好用的方法，r阵可以通过观测噪声来预估，q阵就有点灵魂调参。。。主要是根据状态本身的属性来，具体应用差别很大，
		
		那么如何设置协方差矩阵的初始值：
			P0可以随便设，****不要设太小就行****，一般设P0=k*I，k为一个较大的数即可，反正最终P阵都会收敛。影响滤波器性能的关键是Q和R阵。
			一般P0不能随便设置，虽然说设置较大以后，算法最后可以收敛，但实际效果并不好，尤其在扩展卡尔曼滤波器中，P0值的设置很关键，
			可能会导致算法不收敛。一般P0设置根据sensor的真实精度或者标称精度设置，可以按照3sigma设置。
		
	3.预测观测值的概率密度  z-pred   讲白了就是将预测值转到测量空间下，有一些值是测量不出来的，比如速度
	4.预测观测值的误差的协方差 s-pred
	5.卡尔曼增益 k
	6.更新后验概率密度  xt+1
	7.更新后验误差协方差  pt+1
		这个更新过程是用卡尔曼增益更新的，是不是使得整个协方差矩阵的迹是最小的，算出卡尔曼增益；卡尔曼增益的公式带入的也是前一时刻的协方差矩阵
	8.里面涉及了P状态协方差、Q状态噪声、R测量噪声矩阵，初始化就一次？后续需不需要更新？

	对于一般的公式X = AX_k + BU_k + （wk（noise））,这样的，指的是在追踪一个物体的状态的时候，把内部的控制也考虑进去了，对于其他的车体而言是不知道的，所以直接置零
	noise一般也可以不加？因为均值为0，过程噪声，一般会在predict的时候直接加上，就是公式；由过程噪声就可以写出对我们状态的影响矩阵，把这个矩阵直接分解，单独分解出过程噪声和他前面的矩阵
	进行一个变换求解就可以得到过程噪声的协方差矩阵，Q = E[GUU^TG^T]G^T,代码里面直接带公式计算初始化就完了
	在CTRV里面只会传进来一个initCovarQs(dt, x_merge_(3));  yaw角，其他的一些什么加速度和角加速度的标准差早就被初始化好了
	预测观测值和预测状态类似，UKF里面用点也是类似的，观测矩阵一般都是那种1 1 的矩阵，只是为了把测不出来的状态滤掉，所以sigma点也是直接去权重得到z的，权重和状态的权重略有不同
	
	关于协方差矩阵的理解：https://zhuanlan.zhihu.com/p/37609917
	卡尔曼为什么要用协方差：https://www.zhihu.com/question/437828558/answer/1662838804

	
	回到关联问题上面来
		其目的也很简单，就是为了把多个观测值分配给对应的目标
		关联门的概念就是是一个阈值的选择，越靠近先验分布的中心的地方越可能是真实值，（从几何角度而言这个分布是以均值为中心的一个椭球体）正态分布，3sigma准则
		讲白了就是先验分布根据这个准则，推测出目标出现在这个区域的概率是99.7%；那么这个就叫置信度；调低置信度这个区域就会变大，反之就会变小；
		然后关联门的选择可以是不同形状的。
				
		关联算法：
			最简单粗暴的就是最近邻数据关联，NNDA，直接根据状态或者是协方差矩阵，计算什么欧氏距离或者是马氏距离，排序最小的自然是最近的那么就是关联的目标；
			（NNDA该方法优点在于计算量少，且简单。但是只适用于杂波环境较少的场景，在多杂波场景下，该方法很容易出现错关联的现象，从而跟丢目标，无法保持稳定跟踪。）
			其次是一个航迹分裂，Track split算法，这个算法就是将当前的一个轨迹分成N份，N为观测数量，随着滤波的进行必然后会有N-1个轨迹是区域发散的（针对单个目标），但是非常耗时
			概率数据关联，PDA算法，和NNDA都是针对单目标里面常用的算法，PDA不像NNDA一样只在关联门之内选择一个作匹配的，而是对于每一个关联门之内的都去算一个概率，通过大量的计算算出每个有效的观测值的加权系数，从而计算所有的有效的观测值的加权和作为真实目标观测值的估计，从而在卡尔曼滤波中更新目标的状态。
			JPDA是针对目标密度比较高的情况下的，但是速度也很慢
			
			PDA:autroware好像就没用这个。。。。。

	
	
	补充对于UKF的调参（
	https://blog.csdn.net/xiao_lxl/article/details/100326182?ops_request_misc=&request_id=&biz_id=102&utm_term=UKF&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-6-100326182.142^v10^control,157^v4^control&spm=1018.2226.3001.4187）
	对于CTRV模型，定义了两个噪声，过程噪声。线性加速度和偏航角加速度。
	至于怎么调参，并没有给明确的步骤只是一个大概的：
	1.猜测适当的参数值
	2.运行UKF过滤器
	3.决定结果是否足够好
	4.调整参数并重复该过程
	关于如何调参可以看这个博客里面的东西；
	
			
	
																																																																											
	
'''

























	








